import os
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.font_manager as fm
import platform

# í•œê¸€ í°íŠ¸ ì„¤ì • (ìš´ì˜ì²´ì œì— ë”°ë¼)
if platform.system() == 'Windows':
    plt.rc('font', family='Malgun Gothic')
elif platform.system() == 'Darwin':  # macOS
    plt.rc('font', family='AppleGothic')
else:  # Linux (ì˜ˆ: Colab, Ubuntu)
    import matplotlib
    matplotlib.font_manager._rebuild()
    fm.fontManager.addfont('/usr/share/fonts/truetype/nanum/NanumGothic.ttf')
    plt.rc('font', family='NanumGothic')

# ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€
plt.rcParams['axes.unicode_minus'] = False

# ------------------------ #
# 1. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° ë° ì „ì²˜ë¦¬
# ------------------------ #
input_path = "./split_files/ì„œìš¸_A-ìœ í†µ_ê°ì.csv"
input_filename = os.path.basename(input_path)
base_name = os.path.splitext(input_filename)[0]
df = pd.read_csv(input_path, encoding='euc-kr')
df = df[["PRCE_REG_YMD", "PDLT_PRCE"]].dropna()
df["PRCE_REG_YMD"] = pd.to_datetime(df["PRCE_REG_YMD"], format="%Y%m%d")
df["PDLT_PRCE"] = pd.to_numeric(df["PDLT_PRCE"], errors="coerce")
df = df.dropna().sort_values("PRCE_REG_YMD")

# ------------------------ #
# 2. EDA - ê¸°ë³¸ í†µê³„ ë° ì‹œê°í™”
# ------------------------ #
print("ë°ì´í„° ê°œìˆ˜:", len(df))
print("ë‚ ì§œ ë²”ìœ„:", df["PRCE_REG_YMD"].min(), "â†’", df["PRCE_REG_YMD"].max())
print("ê°€ê²© í†µê³„:\n", df["PDLT_PRCE"].describe())

plt.figure(figsize=(12, 5))
plt.plot(df["PRCE_REG_YMD"], df["PDLT_PRCE"], marker='o')
plt.title("ê°ì ê°€ê²© ì¶”ì´")
plt.xlabel("ë‚ ì§œ"); plt.ylabel("ê°€ê²©"); plt.grid(True)
plt.tight_layout(); plt.show()

plt.figure(figsize=(8, 4))
sns.histplot(df["PDLT_PRCE"], bins=20, kde=True)
plt.title("ê°€ê²© ë¶„í¬")
plt.tight_layout(); plt.show()

df["price_pct"] = df["PDLT_PRCE"].pct_change() * 100
plt.figure(figsize=(12, 4))
plt.plot(df["PRCE_REG_YMD"], df["price_pct"], color='orange')
plt.axhline(0, color='gray', linestyle='--')
plt.title("ì¼ì¼ ê°€ê²© ì¦ê°ë¥  (%)"); plt.grid(True)
plt.tight_layout(); plt.show()

df["MA_7"] = df["PDLT_PRCE"].rolling(7).mean()
df["MA_14"] = df["PDLT_PRCE"].rolling(14).mean()
plt.figure(figsize=(12, 5))
plt.plot(df["PRCE_REG_YMD"], df["PDLT_PRCE"], label="ì‹¤ì œ ê°€ê²©", alpha=0.5)
plt.plot(df["PRCE_REG_YMD"], df["MA_7"], label="7ì¼ ì´ë™ í‰ê· ", linestyle='--')
plt.plot(df["PRCE_REG_YMD"], df["MA_14"], label="14ì¼ ì´ë™ í‰ê· ", linestyle='-.')
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

df["weekday"] = df["PRCE_REG_YMD"].dt.day_name()
weekday_avg = df.groupby("weekday")["PDLT_PRCE"].mean().reindex([
    "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday"
])
plt.figure(figsize=(8, 4))
weekday_avg.plot(kind='bar', color='skyblue')
plt.title("ìš”ì¼ë³„ í‰ê·  ê°€ê²©")
plt.ylabel("í‰ê·  ê°€ê²©")
plt.grid(axis='y'); plt.tight_layout(); plt.show()

# ------------------------ #
# 2-2. EDA ê²°ê³¼ ìš”ì•½ ì €ì¥ (CSV + SQLite)
# ------------------------ #
crop_name = base_name.split("_")[-1]
eda_df = df[["PRCE_REG_YMD", "PDLT_PRCE", "price_pct", "MA_7", "MA_14"]].copy()
eda_df["weekday"] = df["PRCE_REG_YMD"].dt.day_name()
eda_df["crop_name"] = crop_name

eda_output_filename = f"{base_name}_EDA_ìš”ì•½.csv"
eda_df.to_csv(eda_output_filename, index=False, encoding='utf-8-sig')
print(f"ğŸ“Š EDA ìš”ì•½ íŒŒì¼ì´ '{eda_output_filename}'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

import sqlite3
sqlite_filename = f"{base_name}_EDA.sqlite"
table_name = "eda_result"
conn = sqlite3.connect(sqlite_filename)
eda_df.to_sql(table_name, conn, if_exists='replace', index=False)
conn.close()
print(f"ğŸ—‚ï¸ SQLite íŒŒì¼ '{sqlite_filename}'ì— í…Œì´ë¸” '{table_name}'ë¡œ ì €ì¥ ì™„ë£Œ!")
print("ğŸ“Œ ì´ì œ ì´ íŒŒì¼ì„ MySQLì—ì„œ ë¶ˆëŸ¬ì˜¤ë©´ ë©ë‹ˆë‹¤.")

# ------------------------ #
# 3. ë‚ ì§œ ë³´ê°„ ë° ì‹œê³„ì—´ ìƒì„±
# ------------------------ #
full_dates = pd.date_range(start=df["PRCE_REG_YMD"].min(), end=df["PRCE_REG_YMD"].max())
df_full = pd.DataFrame({"PRCE_REG_YMD": full_dates})
df_merged = pd.merge(df_full, df[["PRCE_REG_YMD", "PDLT_PRCE"]], on="PRCE_REG_YMD", how="left")

df_merged["PDLT_PRCE_ffill"] = df_merged["PDLT_PRCE"].ffill()  # ìˆ˜ì •: fillna(method='ffill') â†’ ffill()
scaler = MinMaxScaler()
price_scaled = scaler.fit_transform(df_merged[["PDLT_PRCE_ffill"]])

def create_sequences(data, input_window=30, output_window=14):
    X, y = [], []
    for i in range(len(data) - input_window - output_window):
        X.append(data[i:i+input_window])
        y.append(data[i+input_window:i+input_window+output_window])
    return np.array(X), np.array(y)

X_temp, y_temp = create_sequences(price_scaled, 30, 14)
temp_dataset = TensorDataset(torch.tensor(X_temp, dtype=torch.float32), torch.tensor(y_temp, dtype=torch.float32))
temp_loader = DataLoader(temp_dataset, batch_size=16, shuffle=True)

class CNNBiLSTM(nn.Module):
    def __init__(self, input_size=1, cnn_channels=32, lstm_hidden=128, output_len=14):
        super(CNNBiLSTM, self).__init__()
        self.cnn = nn.Sequential(
            nn.Conv1d(in_channels=input_size, out_channels=cnn_channels, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2)
        )
        self.bilstm = nn.LSTM(input_size=cnn_channels, hidden_size=lstm_hidden,
                              num_layers=1, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(lstm_hidden * 2, output_len)

    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.cnn(x)
        x = x.permute(0, 2, 1)
        output, _ = self.bilstm(x)
        out = self.fc(output[:, -1, :])
        return out.unsqueeze(-1)

model = CNNBiLSTM()
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

for epoch in range(30):
    model.train()
    for xb, yb in temp_loader:
        pred = model(xb)
        loss = criterion(pred, yb)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

filled_prices = df_merged["PDLT_PRCE"].values.copy()
for i in range(len(df_merged)):
    if pd.isna(filled_prices[i]) and i >= 30:
        seq = price_scaled[i-30:i]
        input_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)
        with torch.no_grad():
            pred = model(input_tensor).squeeze().numpy()[0]
        filled_prices[i] = scaler.inverse_transform([[pred]])[0, 0]

df_merged["PDLT_PRCE_filled"] = filled_prices

# ------------------------ #
# 3-2. ì˜¤í† ì¸ì½”ë” ê¸°ë°˜ ì´ìƒì¹˜ íƒì§€ ë° ì²˜ë¦¬
# ------------------------ #

# ì˜¤í† ì¸ì½”ë” ì •ì˜
class Autoencoder(nn.Module):
    def __init__(self, input_size=30):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_size, 16),
            nn.ReLU(),
            nn.Linear(16, 8),
            nn.ReLU(),
            nn.Linear(8, 4)
        )
        self.decoder = nn.Sequential(
            nn.Linear(4, 8),
            nn.ReLU(),
            nn.Linear(8, 16),
            nn.ReLU(),
            nn.Linear(16, input_size)
        )

    def forward(self, x):
        if x.dim() == 3:  # (batch_size, 30, 1)ì¸ ê²½ìš°
            x = x.squeeze(-1)  # (batch_size, 30)ìœ¼ë¡œ ë³€í™˜
        encoded = self.encoder(x)
        decoded = self.decoder(encoded)
        return decoded

# ì˜¤í† ì¸ì½”ë” í•™ìŠµ ë°ì´í„° ì¤€ë¹„
def create_ae_sequences(data, window=30):
    sequences = []
    for i in range(len(data) - window):
        sequences.append(data[i:i+window].flatten())  # (30, 1) -> (30,)
    return np.array(sequences)

# ê°€ê²© ë°ì´í„°ë¥¼ ì •ê·œí™”í•˜ì—¬ ì˜¤í† ì¸ì½”ë” í•™ìŠµ
ae_scaler = MinMaxScaler()
price_scaled_ae = ae_scaler.fit_transform(df_merged[["PDLT_PRCE_filled"]])
ae_sequences = create_ae_sequences(price_scaled_ae, window=30)
print("ae_sequences shape:", ae_sequences.shape)  # ë””ë²„ê¹…ìš©

ae_dataset = TensorDataset(torch.tensor(ae_sequences, dtype=torch.float32))
ae_loader = DataLoader(ae_dataset, batch_size=16, shuffle=True)

# ì˜¤í† ì¸ì½”ë” í•™ìŠµ
ae_model = Autoencoder(input_size=30)
ae_criterion = nn.MSELoss()
ae_optimizer = torch.optim.Adam(ae_model.parameters(), lr=0.001)

for epoch in range(50):
    ae_model.train()
    total_loss = 0
    for batch in ae_loader:
        xb = batch[0]
        recon = ae_model(xb)
        loss = ae_criterion(recon, xb)
        ae_optimizer.zero_grad()
        loss.backward()
        ae_optimizer.step()
        total_loss += loss.item()
    if (epoch + 1) % 10 == 0:
        print(f"Autoencoder Epoch {epoch+1}/50, Loss: {total_loss:.4f}")

# ì´ìƒì¹˜ íƒì§€
ae_model.eval()
recon_errors = []
with torch.no_grad():
    for seq in ae_sequences:
        seq_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)
        recon = ae_model(seq_tensor).squeeze().numpy()
        error = np.mean((seq - recon) ** 2)  # MSE
        recon_errors.append(error)

# ì´ìƒì¹˜ ê¸°ì¤€ ì„¤ì • (ìƒìœ„ 5% ì˜¤ë¥˜ë¥¼ ì´ìƒì¹˜ë¡œ ê°„ì£¼)
threshold = np.percentile(recon_errors, 95)
anomaly_indices = [i for i, error in enumerate(recon_errors) if error > threshold]

# ì´ìƒì¹˜ ì‹œê°í™”
plt.figure(figsize=(12, 5))
plt.plot(df_merged["PRCE_REG_YMD"][30:], df_merged["PDLT_PRCE_filled"][30:], label="ê°€ê²©")
plt.scatter(df_merged["PRCE_REG_YMD"].iloc[anomaly_indices],
            df_merged["PDLT_PRCE_filled"].iloc[anomaly_indices],
            color='red', label="ì´ìƒì¹˜", zorder=5)
plt.title("ì´ìƒì¹˜ íƒì§€ ê²°ê³¼ (ì˜¤í† ì¸ì½”ë”)")
plt.xlabel("ë‚ ì§œ"); plt.ylabel("ê°€ê²©")
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

# ì´ìƒì¹˜ êµì²´ (ì‚¬ì „ í•™ìŠµëœ CNN-BiLSTM ì‚¬ìš©)
corrected_prices = df_merged["PDLT_PRCE_filled"].values.copy()
for idx in anomaly_indices:
    if idx >= 30:
        seq = price_scaled_ae[idx-30:idx]
        input_tensor = torch.tensor(seq, dtype=torch.float32).unsqueeze(0)
        with torch.no_grad():
            pred = model(input_tensor).squeeze().numpy()[0]  # ì²« ë²ˆì§¸ ì˜ˆì¸¡ê°’ ì‚¬ìš©
        corrected_prices[idx] = ae_scaler.inverse_transform([[pred]])[0, 0]

df_merged["PDLT_PRCE_corrected"] = corrected_prices

# ì´ìƒì¹˜ êµì • ê²°ê³¼ ì‹œê°í™”
plt.figure(figsize=(12, 5))
plt.plot(df_merged["PRCE_REG_YMD"], df_merged["PDLT_PRCE_filled"], label="ì›ë³¸ (ë³´ê°„ í›„)", alpha=0.5)
plt.plot(df_merged["PRCE_REG_YMD"], df_merged["PDLT_PRCE_corrected"], label="ì´ìƒì¹˜ êµì • í›„", linestyle='--')
plt.title("ì´ìƒì¹˜ êµì • ì „í›„ ë¹„êµ")
plt.xlabel("ë‚ ì§œ"); plt.ylabel("ê°€ê²©")
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

# ------------------------ #
# 4. ìµœì¢… ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
# ------------------------ #
df_model = df_merged.dropna(subset=["PDLT_PRCE_corrected"])  # êµì •ëœ ë°ì´í„° ì‚¬ìš©
price_scaled_final = scaler.fit_transform(df_model[["PDLT_PRCE_corrected"]])
X_final, y_final = create_sequences(price_scaled_final, 30, 14)
final_dataset = TensorDataset(torch.tensor(X_final, dtype=torch.float32), torch.tensor(y_final, dtype=torch.float32))
final_loader = DataLoader(final_dataset, batch_size=16, shuffle=True)

model = CNNBiLSTM()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
for epoch in range(100):
    model.train()
    total_loss = 0
    for xb, yb in final_loader:
        pred = model(xb)
        loss = criterion(pred, yb)
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        total_loss += loss.item()
    print(f"Epoch {epoch+1}/100, Loss: {total_loss:.4f}")

model.eval()
with torch.no_grad():
    recent_seq = torch.tensor(price_scaled_final[-30:], dtype=torch.float32).unsqueeze(0)
    pred_scaled = model(recent_seq).squeeze().numpy()
    pred_price = scaler.inverse_transform(pred_scaled.reshape(-1, 1)).flatten()

future_dates = pd.date_range(df_model["PRCE_REG_YMD"].max() + pd.Timedelta(days=1), periods=14)
plt.figure(figsize=(10, 5))
plt.plot(df_model["PRCE_REG_YMD"].values[-60:], df_model["PDLT_PRCE_corrected"].values[-60:], label="ì‹¤ì œ ê°€ê²© (ìµœê·¼ 60ì¼)")
plt.plot(future_dates, pred_price, marker='o', label="ì˜ˆì¸¡ ê°€ê²© (í–¥í›„ 14ì¼)")
plt.title("ê°ì ê°€ê²© ì˜ˆì¸¡ (CNN-BiLSTM, ì´ìƒì¹˜ êµì • í›„)")
plt.xlabel("ë‚ ì§œ"); plt.ylabel("ê°€ê²©")
plt.legend(); plt.grid(True); plt.tight_layout(); plt.show()

output_filename = f"{base_name}_ì˜ˆì¸¡_14ì¼_ì´ìƒì¹˜êµì •.csv"
result_df = pd.DataFrame({
    "Date": future_dates,
    "Predicted_Price": pred_price.astype(int)
})
result_df.to_csv(output_filename, index=False, encoding="utf-8-sig")
print(f"ì˜ˆì¸¡ ê²°ê³¼ê°€ '{output_filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")